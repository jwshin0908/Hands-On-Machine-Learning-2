{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c89a0f5",
   "metadata": {},
   "source": [
    "## 1.1 머신러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a25442",
   "metadata": {},
   "source": [
    "Arthur Samuel, 1959 - 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야  \n",
    "**훈련 세트(training set)** : 시스템이 학습하는 데 사용하는 샘플  \n",
    "**훈련 사례(training instance / sample)** : 각 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906302ba",
   "metadata": {},
   "source": [
    "## 1.2 왜 머신러닝을 사용하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22760317",
   "metadata": {},
   "source": [
    "**데이터 마이닝** : 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있음\n",
    "\n",
    "**머신러닝이 효과적인 분야**\n",
    "+ 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제\n",
    "+ 전통적인 방식으로는 해결 방법이 없는 복잡한 문제\n",
    "+ 유동적인 환경\n",
    "+ 복잡한 문제와 대량의 데이터 환경\n",
    "\n",
    "<img src=\"img/1-2.png\" width=\"500px\" align='left'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbce49",
   "metadata": {},
   "source": [
    "## 1.3 애플리케이션 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb38908",
   "metadata": {},
   "source": [
    "+ 생산라인에서 제품 이미지를 분석해 자동으로 분류하기 : CNN  \n",
    "+ 자동으로 뉴스 기사를 분류하기 : NLP, RNN, CNN, Transformer  \n",
    "+ 다양한 성능 지표를 기반으로 회사의 내년도 수익을 예측하기 : regression  \n",
    "+ 음성 명령에 반응하는 앱을 만들기 : RNN, CNN, Transformer  \n",
    "+ 과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기 : 인공 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf9743",
   "metadata": {},
   "source": [
    "## 1.4 머신러닝 시스템의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd577aeb",
   "metadata": {},
   "source": [
    "+ 학습하는 동안의 감독 형태나 정보량에 따라 : 지도 / 비지도 / 준지도 / 강화 학습  \n",
    "+ 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부에 따라 : 온라인 학습 / 배치 학습  \n",
    "+ 어떻게 일반화되는지에 따라 - 사례 기반 학습 / 모델 기반 학습\n",
    "\n",
    "### 1.4.1 지도 학습과 비지도 학습\n",
    "**지도 학습** : 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함됨  \n",
    "+ 분류(classification)\n",
    "+ 회귀(regression) : 예측 변수라 부르는 특성(feature)을 이용해 타깃(target) 수치를 예측하는 것\n",
    "+ 로지스틱 회귀(logistic regression) : 클래스에 속할 확률을 출력\n",
    "\n",
    "e.g. k-최근접 이웃, 선형 회귀, 로지스틱 회귀, 서포트 벡터 머신(SVM), 결정 트리와 랜덤 포레스트, 신경망\n",
    "\n",
    "**비지도 학습** : 훈련 데이터에 레이블이 없음. 시스템이 아무 도움 없이 학습해야 함\n",
    "+ 군집(clustering) : 계층 군집 알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화 가능 / e.g. k-평균, DBSCAN, 계층 군집 분석\n",
    "+ 시각화(visualization) : 데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상하지 못한 패턴을 발견할 수도 있음\n",
    "+ 차원 축소(dimensionality reduction) : 너무 많은 정보를 잃지 않으면서 데이터를 간소화함\n",
    "+ 특성 추출(feature extraction) : 상관관계가 있는 여러 특성을 하나로 합침\n",
    "+ 이상치 탐지(outlier detection) : 학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거하기\n",
    "+ 특이치 탐지(novelty detection) : 훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적\n",
    "+ 연관 규칙 학습(association rule learning) : 대량의 데이터에서 특성 간의 흥미로운 관계를 찾음\n",
    "\n",
    "**준지도 학습** : 일부만 레이블이 있는 데이터를 다룸. 비지도 학습으로 군집을 찾은 후에 정답이 있는 샘플을 사용해 지도 학습 알고리즘을 학습\n",
    "+ 심층 신뢰 신경망(DBN) : 여러 겹으로 쌓은 제한된 볼츠만 머신(RBM)이라 불리는 비지도 학습에 기초\n",
    "<img src=\"img/1-11.png\" width=\"500px\">\n",
    "\n",
    "\n",
    "**강화 학습** : 환경을 관찰해서 행동을 실행하고 그 결과로 보상 또는 벌점을 받음. 가장 큰 보상을 얻기 위해 정책이라 부르는 최상의 전략을 스스로 학습\n",
    "<img src=\"img/1-12.png\" width=\"500px\">  \n",
    "\n",
    "### 1.4.2 배치 학습과 온라인 학습\n",
    "**배치 학습** : 시스템이 점진적으로 학습할 수 없고 가용한 데이터를 모두 사용해 훈련시켜야 함  \n",
    "+ 오프라인 학습(offline learning) : 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행됨. 즉, 학습한 것을 단지 적용함\n",
    "+ 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야 함\n",
    "+ 전체 데이터셋을 사용해 훈련한다면 많은 컴퓨팅 자원이 필요함\n",
    "\n",
    "**온라인 학습** : 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련\n",
    "+ 매 학습 단계가 빠르고 비용이 적게 듦\n",
    "+ 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야하는 시스템에 적합\n",
    "+ 시스템에 나쁜 데이터가 주입되었을 때 성능이 점진적으로 감소함\n",
    "+ 학습률(learning rate) : 변화하는 데이터에 얼마나 빠르게 적응할 것인가\n",
    "    + 높을 경우 : 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림\n",
    "    + 낮을 경우 : 시스템의 관성이 더 커져서 더 느리게 학습되지만, 새로운 데이터에 있는 잡음에 덜 민감해짐\n",
    "\n",
    "### 1.4.3 사례 기반 학습과 모델 기반 학습\n",
    "**사례 기반 학습** : 시스템이 훈련 샘플을 기억함으로써 학습. 이후 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 방식\n",
    "\n",
    "**모델 기반 학습** : 샘플들의 모델을 만들어 예측에 사용하는 것\n",
    "\n",
    "**머신러닝 프로젝트의 형태**\n",
    "+ 데이터를 분석\n",
    "+ 모델을 선택\n",
    "+ 훈련 데이터로 모델을 훈련(학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾음)\n",
    "+ 새로운 데이터에 모델을 적용해 예측, 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a5d3b",
   "metadata": {},
   "source": [
    "## 1.5 머신러닝의 주요 도전 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d019db",
   "metadata": {},
   "source": [
    "### 1.5.1 충분하지 않은 양의 훈련 데이터\n",
    "아주 간단한 문제에서조차도 수천 개의 데이터가, 이미지나 음성 인식 같은 복잡한 문제라면 수백만 개가 필요할 수도 있음\n",
    "\n",
    "### 1.5.2 대표성 없는 훈련 데이터\n",
    "샘플이 작으면 샘플링 잡음(sampling noise, 우연에 의한 대표성 없는 데이터) / 표본 추출 방법이 잘못되면 샘플링 편향(sampling bias)\n",
    "\n",
    "### 1.5.3 낮은 품질의 데이터\n",
    "훈련 데이터가 에러, 이상치, 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않음\n",
    "\n",
    "### 1.5.4 관련 없는 특성\n",
    "**특성 공학(feature engineering)** : 훈련에 사용할 좋은 특성들을 찾는 것\n",
    "+ 특성 선택(feature selection) : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택\n",
    "+ 특성 추출(feature extraction) : 특성을 결합하여 더 유용한 특성을 만듦\n",
    "\n",
    "### 1.5.5 훈련 데이터 과대적합\n",
    "**과대적합(overfitting)** : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐\n",
    "\n",
    "**해결 방법**\n",
    "+ 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킴\n",
    "+ 훈련 데이터를 더 많이 모음\n",
    "+ 훈련 데이터의 잡음을 줄임(오류 데이터 수정, 이상치 제거)\n",
    "\n",
    "**규제(regularization)** : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것\n",
    "\n",
    "**하이퍼파라미터(hyperparameter)** : 학습 알고리즘의 파라미터. 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련 동안 상수 취급\n",
    "### 1.5.6 훈련 데이터 과소적합\n",
    "**과소적합(underfitting)** : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생\n",
    "\n",
    "**해결 방법**\n",
    "+ 모델 파라미터가 더 많은 강력한 모델을 선택\n",
    "+ 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)\n",
    "+ 모델의 제약을 줄임(규제 하이퍼파라미터 감소)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef63d8",
   "metadata": {},
   "source": [
    "## 1.6 테스트와 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813965d",
   "metadata": {},
   "source": [
    "훈련 데이터를 훈련 세트와 테스트 세트 두 개로 나눔\n",
    "\n",
    "훈련 세트를 사용해 모델을 훈련하고 테스트 세트를 사용해 모델을 테스트함\n",
    "\n",
    "### 1.6.1 하이퍼파라미터 튜닝과 모델 선택\n",
    "**홀드아웃 검증(holdout validation)** : 간단하게 훈련 세트의 일부분(검증 세트, validation set)을 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택\n",
    "+ 줄어든 훈련 세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련\n",
    "+ 검증 세트에서 가장 높은 성능을 내는 모델을 선택\n",
    "+ 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만듦\n",
    "+ 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정\n",
    "\n",
    "**교차 검증(cross-validation)** : 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가\n",
    "\n",
    "**훈련-개발 세트(train-dev set)** : 검증, 테스트 세트에 사용되는 데이터와 훈련 세트 사이에 데이터 불일치 위험이 있을 때 사용\n",
    "+ 훈련 세트의 일부에서 모델을 훈련하고 훈련-개발 세트와 검증 세트에서 평가\n",
    "    + 과대적합 : 훈련 세트에서 잘 작동하지만 훈련-개발 세트에서 나쁜 성능\n",
    "    + 데이터 불일치 : 훈련 세트와 훈련-개발 세트에서 양쪽에서 모두 잘 동작하지만 검증 세트에서 성능이 나쁠 경우"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
